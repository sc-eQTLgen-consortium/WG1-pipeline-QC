#!/usr/local/envs/py36/bin python3
import os
import pandas as pd

# Add trailing /.
if not config["refs"]["ref_dir"].endswith("/"):
    config["refs"]["ref_dir"] += "/"
if not config["outputs"]["output_dir"].endswith("/"):
    config["outputs"]["output_dir"] += "/"

# Check if input files exist.
for input_path in ["pgen_path", "pvar_path", "psam_path"]:
    if not os.path.exists(config["inputs"][input_path]):
        logger.info("Could not find the {} file. Please check that the file exists.\n\n Exiting.".format(config["inputs"][input_path]))
        exit()
logger.info("Using these files as input:")
logger.info("The pgen file: " + config["inputs"]["pgen_path"])
logger.info("The pvar file: " + config["inputs"]["pvar_path"])
logger.info("The psam file: " + config["inputs"]["psam_path"] + "\n")

# Check if reference files exist.
for ref_path in ["relative_vcf_path", "relative_fasta_path", "relative_map_path", "relative_imputation_path"]:
    if not os.path.exists(config["refs"]["ref_dir"] + config["refs_extra"][ref_path]):
        logger.info("Could not find the {} file. Please check that the file exists.\n\n Exiting.".format(config["refs"]["ref_dir"] + config["refs_extra"][ref_path]))
        exit()
logger.info("Found all the required reference files in " + config["refs"]["ref_dir"] + "\n")

# Check if the CHR column in the PVAR file contains the word 'chr'.
chr_in_pvar = False
with open(config["inputs"]["pvar_path"]) as f:
    for line in f:
        if "chr" in line:
            chr_in_pvar = True
            break
f.close()
if chr_in_pvar:
    logger.info("Looks like your chromosome encoding uses chr before the chromosome. For this pipeline, the chromosome encoding should not use chr. Please remove the 'chr' from your pvar file and try again. Exiting.")
    exit()

required_columns = {
    '#FID': (False, False, {}),
    'IID': (False, False, {}),
    'PAT': (True, False, {}),
    'MAT': (True, False, {}),
    'SEX': (True, False, {1: "male", 2: "female", 0: "unknown"}),
    'Provided_Ancestry': (False, True, {"AFR": "African",
                                        "AMR": "Ad Mixed American",
                                        "EAS": "East Asian",
                                        "EUR": "European",
                                        "SAS": "South Asian",
                                        "NA": "unknown"}),
    'genotyping_platform': (False, True, {}),
    'array_available': (False, True, {"Y": "yes", "N": "no"}),
    'wgs_available': (False, True, {"Y": "yes", "N": "no"}),
    'wes_available': (False, True, {"Y": "yes", "N": "no"}),
    'age': (True, True, {}),
    'age_range': (False, True, {}),
    'Study': (False, False, {}),
    'smoking_status': (False, True, {"yes": "smokes at time of sample collection",
                                     "past": "smoked in the past but not at time of sample collection",
                                     "no": "never smoked",
                                     "NA": "unknown smoking status"}),
    'hormonal_contraception_use_currently': (False, True, {"yes": "currently using hormonal contraception",
                                                           "no": "not currently using hormonal contraception",
                                                           "NA": "unknown status of contraception use or male"}),
    'menopause': (False, True, {"pre": "have not yet gone through menopause",
                                "menopause": "currently going through menopause",
                                "post": "completed menopause",
                                "NA": "unknown menopause status or male"}),
    'pregnancy_status': (False, True, {"yes": "pregnant at time of sample collection",
                                       "no": "not pregnant at time of sample collection",
                                       "NA": "unknown pregnancy status or male"})
}

# Validate the input PSAM file.
psam_df = pd.read_csv(config["inputs"]["psam_path"], sep="\t")
psam_df.fillna("NA", inplace=True)
missing_columns = [column for column in required_columns.keys() if not column in psam_df.columns]
if len(missing_columns) > 0:
    logger.info("The column names of your psam file are not correct.\n\
            The columns that you are missing or whose spelling does not match the required input is/are:\n{}\n\
            They should be: '#FID', 'IID', 'PAT', 'MAT', 'SEX', 'Provided_Ancestry','genotyping_platform', 'array_available', 'wgs_available','wes_available', 'age', 'age_range', 'Study', 'smoking_status', 'hormonal_contraception_use_currently', 'menopause',  'pregnancy_status'.\n\
            If the names look the same, check that the file is tab separated, without any spaces or other weird characters.\n\n\
            Exiting.".format("\n".join(missing_columns)))
    exit()

### Check for underscores in the FID and IID columns - if there are, update and make new files
for column, column_description in [("#FID", "family ids"), ("IID", "individual ids")]:
    if psam_df[column].str.contains("_").any():
        logger.info("Your {} in the psam ({} column) contain '_'.\
        Underscores are not allowed in this column due to plink operations.\n\
        Updating to dashes ('-').".format(column_description, column))
        exit()

# Check if the other columns are valid as well.
for column, (is_numeric, na_allowed, valid_values) in required_columns.items():
    # Check if numeric if need be. Some columns can have NA so then we need to only check the non NA rows.
    if is_numeric:
        values = psam_df[column]
        if na_allowed:
            values = psam_df.loc[psam_df[column] != "NA", column]
        for value in values:
            if not value.isnumeric():
                logger.info("Your {} column is not numeric, please make sure there are only numeric values in this column.\n\
                Exiting.".format(column))
                exit()

    # TODO; empty string is allowed?
    # Check if there are None or NA in the column.
    if not na_allowed and "NA" in psam_df[column]:
        logger.info("Your {} column is missing entires. NA values are not allowed in this column.\n\
        Please make sure that all contents of the study column have a string entry.\n\
        Exiting.".format(column))
        exit()

    # Check if the values correspond with the accepted input values.
    if valid_values and not psam_df[column].isin(valid_values.keys()).all():
        logger.info("Your {} column does not have just {}, please make sure all values in this column are {}.\n\
        Exiting.".format(column, ", ".join(valid_values), ", ".join(["{} ({})".format(key, value) for key, value in valid_values.items()])))
        exit()

# TODO: Not checking for np.nan, expecting all values to be non NA.
# Check that the female columns are all NA for the males.
for female_column in ["hormonal_contraception_use_currently", "menopause", "pregnancy_status"]:
    if not (psam_df.loc[psam_df["SEX"] == 1, female_column] == "NA").all():
        logger.info("There is a conflict between you SEX and your {} columns.\n\
         All males (coded by 1 in SEX) must be NA for hormonal_contraception_use_currently.\n\
         Please fix this before running the pipeline.\n\
         Exiting.".format(female_column))
        exit()

#####################
######## ALL ########
#####################
chromosomes = [i for i in range(1, 23)]

# TODO: maybe better to split this per manual_selection file?
plinkQC_files = []
impute_files = []
if os.path.exists(config["outputs"]["output_dir"] + "/pca_sex_checks/ancestry_update_remove.tsv") and os.path.exists(config["outputs"]["output_dir"] + "/pca_sex_checks/check_sex_update_remove.tsv"):
    ancestry_check = pd.read_csv(config["outputs"]["output_dir"] + "/pca_sex_checks/ancestry_update_remove.tsv", sep="\t")
    sex_check = pd.read_csv(config["outputs"]["output_dir"] + "/pca_sex_checks/check_sex_update_remove.tsv", sep="\t")
    if ancestry_check["UPDATE/REMOVE/KEEP"].count() == len(ancestry_check) and pd.Series(ancestry_check["UPDATE/REMOVE/KEEP"]).isin(['UPDATE','REMOVE','KEEP']).all() and sex_check["UPDATE/REMOVE/KEEP"].count() == len(sex_check) and pd.Series(sex_check["UPDATE/REMOVE/KEEP"]).isin(['UPDATE','REMOVE','KEEP']).all():
        if not os.path.exists(config["outputs"]["output_dir"] + "/pca_sex_checks/ancestry_mafs.tsv"):
            # TODO: why use live user input here? They can just adjust the file. Seems safer.
            ##### First, need to provide users summary of the ancestries and get interactive allele frequency selections ###
            ### if there are any individuals chosen to remove, remove them from the psam
            psam_df_local = psam_df

            ### if htere are any individuals chosen to update the ancestry, update them
            if (ancestry_check["UPDATE/REMOVE/KEEP"] == "UPDATE").any():
                ids2update = ancestry_check['IID'][ancestry_check["UPDATE/REMOVE/KEEP"] == "UPDATE"].values
                updates = pd.DataFrame(ancestry_check['PCA_Assignment'][ancestry_check["UPDATE/REMOVE/KEEP"] == "UPDATE"])
                updates.index = ids2update
                updates.columns =['Provided_Ancestry']
                psam_df_local.index = psam_df_local.IID.values
                psam_df_local.update(updates)

            psam_df_local.to_csv(config["outputs"]["output_dir"] + "/pca_sex_checks/updated_psam.psam", sep="\t" ,na_rep="NA", index=False)

            ### identify the ancestries in total and provide user input for maf selection
            uniq_ancestries = psam_df_local['Provided_Ancestry'].unique()

            maf_df = pd.DataFrame(columns=['Ancestry','MAF'])
            i = 0
            for pop in uniq_ancestries:
                impute_prompt = input("You have " + str(len(psam_df_local[psam_df_local['Provided_Ancestry'].str.contains(pop)])) + " individuals from " + pop + " ancestry.\nWould you like to impute for this ancestral population? (yes/no)\n").lower()

                if impute_prompt == 'yes' or impute_prompt == 'y':
                    maf_prompt = float(input("\nWhat minor allele frequency filtering would you like to use for pre-imputation processing for the " + pop + " ancestry group.\nA value of 0.05 removes SNPs with < 5% minor alleles from the analysis.\nFor no filtering use 0.\n(0-1)\n"))

                    maf_df.loc[i] =[pop, maf_prompt]

                else:
                    logger.info("Your response indicated that you don't want to impute individuals from " + pop + " ancestry.\nMoving to next ancestrys (if applicable).")

                i = +1 #TODO this is a typo

            maf_df.to_csv(config["outputs"]["output_dir"] + "/pca_sex_checks/ancestry_mafs.tsv", sep="\t", na_rep="NA")

        maf_df = pd.read_csv(config["outputs"]["output_dir"] + "/pca_sex_checks/ancestry_mafs.tsv", sep="\t")
        ancestry_subsets = maf_df['Ancestry'].values

        ### Choose MAF for each group ###
        plinkQC_files.append(config["outputs"]["output_dir"] + "/update_sex_ancestry/update_sex.pgen")

        plinkQC_files.append(expand(config["outputs"]["output_dir"] + "/subset_ancestry/{ancestry}_individuals.psam", ancestry=ancestry_subsets))
        impute_files.append(expand(config["outputs"]["output_dir"] + "/minimac_imputed/{ancestry}_chr{chr}.dose.vcf.gz", ancestry=ancestry_subsets, chr=chromosomes))
        impute_files.append(config["outputs"]["output_dir"] + "/genotype_donor_annotation/genotype_donor_annotation.tsv")
        impute_files.append(expand(config["outputs"]["output_dir"] + "/vcf_merged_by_ancestries/{ancestry}_imputed_hg38.vcf.gz.csi",ancestry=ancestry_subsets))
        impute_files.append(config["outputs"]["output_dir"] + "/vcf_4_demultiplex/imputed_hg38_R2_0.3_MAF0.05_exons_sorted.vcf")
        impute_files.append(config["outputs"]["output_dir"] + "/vcf_all_merged/imputed_hg38_R2_0.3_MAF0.05_exons_complete_cases.recode.vcf")
        impute_files.append(config["outputs"]["output_dir"] + "/metrics/Number_SNPs.png")
        impute_files.append(config["outputs"]["output_dir"] + "/metrics/ancestry_summary.png")
        impute_files.append(config["outputs"]["output_dir"] + "/metrics/sex_summary.png")

    else:

        missing_sex = set(sex_check['IID'].astype(str)[[not elem for elem in list(sex_check["UPDATE/REMOVE/KEEP"].isin(pd.Series(['UPDATE', 'REMOVE', 'KEEP'])))]])
        missing_sex_string = "\n".join(missing_sex)

        missing_ancestry = set(ancestry_check['IID'].astype(str)[[not elem for elem in list(ancestry_check["UPDATE/REMOVE/KEEP"].isin(pd.Series(['UPDATE', 'REMOVE', 'KEEP'])))]])
        missing_ancestry_string = "\n".join(missing_ancestry)

        if len(missing_sex) > 0 and len(missing_ancestry) > 0:
            logger.info("\nERROR: The UPDATE/REMOVE/KEEP column in the pca_sex_checks/ancestry_update_remove.tsv and the pca_sex_checks/check_sex_update_remove.tsv file are not completed.\n\nSpecifically, these individuals do not have appropriate inputs for the UPDATE/REMOVE/KEEP column in the 'check_sex_update_remove.tsv' file:\n" + missing_sex_string + "\nSpecifically, these individuals do not have appropriate inputs for the UPDATE/REMOVE/KEEP column in the 'ancestry_update_remove.tsv' file: " + missing_ancestry_string + "\n\nPlease fill in these selections for the pipeline to continue.\nPlease see https://github.com/sc-eQTLgen-consortium/WG1-pipeline-QC/wiki/1---SNP-Genotype-Imputation#running-the-pipeline---final-qc-and-vcf-production for more details.\n\n")

        elif len(missing_sex) > 0:
            logger.info("\nERROR: The UPDATE/REMOVE/KEEP column in the pca_sex_checks/check_sex_update_remove.tsv file is not completed.\n\nSpecifically, these individuals do not have appropriate inputs for the UPDATE/REMOVE/KEEP column in the 'check_sex_update_remove.tsv' file:\n" + missing_sex_string + "\nPlease fill in these selections for the pipeline to continue.\n\nPlease see https://github.com/sc-eQTLgen-consortium/WG1-pipeline-QC/wiki/1---SNP-Genotype-Imputation#running-the-pipeline---final-qc-and-vcf-production for more details.\n\n")

        elif len(missing_ancestry) > 0:
            logger.info("\nERROR: The UPDATE/REMOVE/KEEP column in the pca_sex_checks/check_sex_update_remove.tsv file is not completed.\n\nSpecifically, these individuals do not have appropriate inputs for the UPDATE/REMOVE/KEEP column in the 'ancestry_update_remove.tsv' file:\n" + missing_ancestry_string + "\nPlease fill in these selections for the pipeline to continue.\n\nPlease see https://github.com/sc-eQTLgen-consortium/WG1-pipeline-QC/wiki/1---SNP-Genotype-Imputation#running-the-pipeline---final-qc-and-vcf-production for more details.\n\n")

        else:
            logger.info("\nERROR: The UPDATE/REMOVE/KEEP column in the pca_sex_checks/ancestry_update_remove.tsv and/or the pca_sex_checks/check_sex_update_remove.tsv file are not completed.\n\nWe were unable to identify the exact individuals that contained the issue.\n\nPlease fill in these selections for the pipeline to continue.\nPlease see https://github.com/sc-eQTLgen-consortium/WG1-pipeline-QC/wiki/1---SNP-Genotype-Imputation#running-the-pipeline---final-qc-and-vcf-production for more details.")
else:
    plinkQC_files.append(config["outputs"]["output_dir"] + "/pca_sex_checks/ancestry_update_remove.tsv")

rule all:
    input:
        plinkQC_files,
        impute_files

############################
######## IMPUTATION ########
############################

# Import individual rules
include: "includes/plink_gender_ancestry_QC.smk"
include: "includes/urmo_imputation_hg38.smk"
