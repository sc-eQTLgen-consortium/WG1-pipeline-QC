#!/usr/bin/env python
import os
import sys
import pandas as pd
from glob import glob
import subprocess
import shutil


# Import custom functions
from mods import prepareArguments
from mods import read10x


### Extract variables from configuration file for use within the rest of the pipeline
config = prepareArguments.parsePaths(config)
input_dict = config["inputs"]
output_dict = config["outputs"]
ref_dict = config["refs"]
bind_path = input_dict["bind_path"]


# Rule-specific arguments
popscle_dict = config["popscle"]
popscle_extra_dict = config["popscle_extra"]
souporcell_dict = config["souporcell"]
souporcell_extra_dict = config["souporcell_extra"]
DoubletDetection_dict = config["DoubletDetection"]
DoubletDetection_manual_dict = config["DoubletDetection_manual"]
DoubletDetection_extra_dict = config["DoubletDetection_extra"]
scrublet_dict = config["scrublet"]
scrublet_manual_dict = config["scrublet_manual"]
scrublet_extra_dict = config["scrublet_extra"]
scds_dict = config["scds"]
CombineResults_dict = config["CombineResults"]


# Use prepareArguments.py script to retrieve exact directories of single cell files
scrnaseq_libs_df = prepareArguments.get_scrnaseq_dirs(config)
scrnaseq_libs_df.to_csv(os.path.join(output_dict["output_dir"],'file_directories.txt'), sep = "\t", index = False)
samples = pd.read_csv(input_dict["samplesheet_filepath"], sep = "\t")
samples.columns = ["Pool", "N"]


fasta = prepareArguments.getFASTA(ref_dict["ref_dir"])


# If the scrublet_check output is present => all the contents are there that are needed to move past 
if os.path.exists(os.path.join(output_dict["output_dir"], "scrublet/scrublet_check.done")):
    scrublet_decisions = pd.read_csv(os.path.join(output_dict["output_dir"], "manual_selections/scrublet_gene_pctl.txt"), sep = "\t")


# Import individual rules
include: "includes/Snakefile_popscle.smk"
include: "includes/Snakefile_scrublet.smk"
include: "includes/Snakefile_souporcell.smk"
include: "includes/Snakefile_scds.smk"
include: "includes/Snakefile_DoubletDetection.smk"
include: "includes/Snakefile_CombineResults.smk"


# Generate list of files to expect
## Demuxlet
demuxlet_files = []
demuxlet_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/demuxlet_results.txt",  pool=samples.Pool))

## Souporcell
souporcell_files = []
souporcell_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/souporcell_results.txt", pool=samples.Pool))
souporcell_files.append(expand(output_dict["output_dir"] + "/{pool}/souporcell/Individual_genotypes_subset.vcf.gz", pool=samples.Pool))

## scds
scds_files = []
scds_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/scds_results.txt", pool=samples.Pool))

## scrublet 
## the scrublet files that will be run are dependent on user inputs in the yaml file
scrublet_files = []
scrublet_files.append(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv")
if os.path.exists(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv"):
    scrublet_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv", sep = "\t")
    logger.info("Read in the scrublet manual selection file.")
    if scrublet_selection["scrublet_Percentile"].count() == len(scrublet_selection):
        logger.info("All the scrublet results have been selected. Will move to next steps.")
        scrublet_selection["scrublet_Percentile"] = scrublet_selection["scrublet_Percentile"].astype(int)
        scrublet_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/{pctl}_scrublet_results.txt", zip, pool=scrublet_selection.Pool, pctl = scrublet_selection.scrublet_Percentile))
    elif scrublet_selection["scrublet_Percentile"].count() != len(scrublet_selection):
        logger.info("The scrublets results did not all PASS. Waiting for them to be competed and thresholds selected.")
        if scrublet_manual_dict["run_scrublet_manual"] == False:
            logger.info("Running the default scrublet rules since 'run_scrublet_manual' is set to False.")
            scrublet_files.append(expand(output_dict["output_dir"] + "/{pool}/scrublet_{pctl}/default_run_variables.txt", pool = samples.Pool, pctl = scrublet_dict["percentile"]))
        elif scrublet_manual_dict["run_scrublet_manual"] == True:
            logger.info("Running scrublet rules with manual selections since 'run_scrublet_manual' is set to True.")
            scrublet_files.append(expand(output_dict["output_dir"] + "/{pool}/scrublet_{pctl}/manual_rerun_variables.txt",zip, pool = scrublet_manual_dict["scrublet_manual_threshold_pools"], pctl = scrublet_manual_dict["scrublet_manual_threshold_percentiles"]))
            logger.info("Deleting the scrublet results and rerunning since 'run_scrublet_manual' is set to True but results exist.")
            ### remove the files to force the rule to run if still needing to rerun (will only happen if manual selections aren't filled in all the way)
            for f in expand(output_dict["output_dir"] + "/{pool}/scrublet_{pctl}/manual_rerun_variables.txt",zip, pool = scrublet_manual_dict["scrublet_manual_threshold_pools"], pctl = scrublet_manual_dict["scrublet_manual_threshold_percentiles"]):
                fname = f.rstrip() 
                if os.path.isfile(fname): 
                    os.remove(fname)
## DoubletDetection
DoubletDetection_files = []
DoubletDetection_files.append(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv")
if os.path.exists(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv"):
    DoubletDetection_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv", sep = "\t")
    logger.info("Read in the DoubletDetection manual selection file.")
    if len(DoubletDetection_selection[DoubletDetection_selection['DoubletDetection_PASS_FAIL'].astype(str).str.contains('PASS', na=False)]) == len(DoubletDetection_selection):
        logger.info("All the DoubletDetection results have PASSED. Will move to next steps.")
        DoubletDetection_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/DoubletDetection_results.txt", pool=DoubletDetection_selection.Pool))
    elif len(DoubletDetection_selection[DoubletDetection_selection['DoubletDetection_PASS_FAIL'].astype(str).str.contains('PASS', na=False)]) != len(DoubletDetection_selection):
        logger.info("The DoubletDetection results did not all PASS. Waiting for them to be competed and PASS.")
        if DoubletDetection_manual_dict["run_DoubletDetection_manual"] == False:
            logger.info("Running the default DoubletDetection rules since 'run_DoubletDetection_manual' is set to False.")
            DoubletDetection_files.append(expand(output_dict["output_dir"] + "/{pool}/DoubletDetection/default_run_variables.txt", pool = samples.Pool))
        elif DoubletDetection_manual_dict["run_DoubletDetection_manual"] == True:
            logger.info("Running DoubletDetection for specified rules since 'run_DoubletDetection_manual' is set to True.")
            DoubletDetection_files.append(expand(output_dict["output_dir"] + "/{pool}/DoubletDetection/manual_rerun_variables.txt", pool = DoubletDetection_manual_dict["DoubletDetection_manual_pools"]))
            logger.info("Deleting the DoubletDetection results and rerunning since 'run_DoubletDetection_manual' is set to True but results exist.")
            ### remove the files to force the rule to run if still needing to rerun (will only happen if manual selections aren't filled in all the way)
            for f in expand(output_dict["output_dir"] + "/{pool}/DoubletDetection/manual_rerun_variables.txt", pool = DoubletDetection_manual_dict["DoubletDetection_manual_pools"]):
                fname = f.rstrip() 
                if os.path.isfile(fname): 
                    os.remove(fname)

## Combined files at the end
combined_files = []
if os.path.exists(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv") and os.path.exists(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv"):
    logger.info("Found the 'crublet_percentile_manual_selection.tsv' and DoubletDetection_manual_selection.tsv files. Reading in.")
    scrublet_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv", sep = "\t")
    DoubletDetection_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv", sep = "\t")
    if scrublet_selection["scrublet_Percentile"].count() == len(scrublet_selection) and len(DoubletDetection_selection[DoubletDetection_selection['DoubletDetection_PASS_FAIL'].astype(str).str.contains('PASS', na=False)]) == len(DoubletDetection_selection):
        logger.info("All the DoubletDetection results have PASSED and thresholds selected for scrublet. Will move to next steps.")
        combined_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/Final_Assignments_demultiplexing_doublets.txt", pool = samples.Pool))
        combined_files.append(output_dict["output_dir"] + "/QC_figures/UMI_vs_Genes_QC_scatter.png")
    else:
        logger.info("The DoubletDetection and scrublet results were not complete. Once they are complete, the results can be combined and downstream analyses completed.")

# Main rule - input will be all files generated at the top
rule all:
    input:
        demuxlet_files,
        souporcell_files,
        scds_files,
        scrublet_files,
        DoubletDetection_files,
        combined_files
