#!/usr/bin/env python
import os
import pandas as pd
from mods import prepareArguments
from mods import consts

### Extract variables from configuration file for use within the rest of the pipeline
ref_dict = config["refs"]
input_dict = config["inputs"]
output_dict = config["outputs"]
settings_dict = config["settings"]

# Remove trailing slashes.
ref_dict["ref_dir"] = ref_dict["ref_dir"].rstrip("/")
input_dict["sc_rnaseq_dir"] = input_dict["sc_rnaseq_dir"].rstrip("/")
input_dict["individual_list_dir"] = input_dict["individual_list_dir"].rstrip("/")
output_dict["output_dir"] = output_dict["output_dir"].rstrip("/")

if not isinstance(settings_dict["is_multiplexed"], bool):
    logger.info("\nERROR: the 'is_multiplexed' variable in the configuration file is not a boolean. Please use True or False.\n\n Exiting.")
    exit()
methods = []
if settings_dict["is_multiplexed"]:
    methods.extend(consts.DEMULTIPLEX)

if settings_dict["sc_data_type"] == "single-cell":
    methods.extend(consts.SINGLE_CELL)
elif settings_dict["sc_data_type"] == "single-nucleus":
    methods.extend(consts.SINGLE_NUCLEUS)
else:
    logger.info("\nERROR: the 'sc_data_type' variable in the configuration file is not recognised. Please use 'single-cell' or 'single-nucleus'.\n\n Exiting.")
    quit()

if not os.path.isdir(output_dict["output_dir"]):
    os.mkdir(output_dict["output_dir"])

logger.info("read in sample info")
samples_df = pd.read_csv(input_dict["samplesheet_filepath"], sep="\t")
samples_df = samples_df.iloc[:2, :] #TODO: remove
samples_df.columns = ["Pool", "N"]
samples_df["Pool"] = samples_df["Pool"].astype(str)
n_pools = samples_df.shape[0]

# Use prepareArguments.py script to retrieve exact directories of single cell files
logger.info("find the necessary input files in the scRNA-seq directories.")
scrnaseq_libs_df = prepareArguments.get_scrnaseq_dirs(config=config, samples_df=samples_df)
scrnaseq_libs_df.to_csv(os.path.join(output_dict["output_dir"], 'file_directories.txt'), sep="\t", index=False)

# Define a list for all outpu files we need.
combine_results_dict = config["combine_results"]
combine_results_extra_dict = config["combine_results_extra"]
combine_results_extra_dict["combine_results_files"] = {pool: {method: [] for method in ["demuxlet",
                                                                                        "souporcell",
                                                                                        "souporcell_assignments",
                                                                                        "souporcell_correlation_limit",
                                                                                        "DoubletFinder",
                                                                                        "scDblFinder",
                                                                                        "DoubletDetection",
                                                                                        "scds",
                                                                                        "Scrublet"]} for pool in samples_df["Pool"]}
combine_results_extra_dict["souporcell_genotype_correlation_threshold"] = None

# popscle - demuxlet
# demuxlet_files = []
if "popscle" in methods:
    popscle_dict = config["popscle"]
    popscle_extra_dict = config["popscle_extra"]

    # demuxlet_files = [os.path.join(output_dict["output_dir"], pool, "popscle", "demuxlet", "demuxletOUT.best") for pool in samples_df["Pool"]]
    for pool in samples_df["Pool"]:
        combine_results_extra_dict["combine_results_files"][pool]["demuxlet"] = os.path.join(output_dict["output_dir"], pool, "popscle", "demuxlet", "demuxletOUT.best")
    include: "includes/Snakefile_popscle.smk"  # demultiplexing + doublet detection

# souporcell
# souporcell_files = []
# souporcell_assignments_files = []
combine_results_extra_dict["souporcell_genotype_correlation_threshold"] = None
if "souporcell" in methods:
    souporcell_dict = config["souporcell"]
    souporcell_extra_dict = config["souporcell_extra"]

    souporcell_size_dict = {row["Pool"]: row["N"] for _, row in samples_df.iterrows()}
    # souporcell_files = [os.path.join(output_dict["output_dir"], pool, "souporcell", "clusters.tsv") for pool in samples_df["Pool"]]
    # souporcell_assignments_files = [os.path.join(output_dict["output_dir"], pool, "souporcell", "genotype_correlations", "Genotype_ID_key.txt") for pool in samples_df["Pool"]]
    for pool in samples_df["Pool"]:
        combine_results_extra_dict["combine_results_files"][pool]["souporcell"] = os.path.join(output_dict["output_dir"], pool, "souporcell", "clusters.tsv")
        combine_results_extra_dict["combine_results_files"][pool]["souporcell_assignments"] = os.path.join(output_dict["output_dir"], pool, "souporcell", "genotype_correlations", "Genotype_ID_key.txt")

    combine_results_extra_dict["combine_results_files"]["souporcell_genotype_correlation_threshold"] = souporcell_dict["souporcell_genotype_correlation_threshold"]
    include: "includes/Snakefile_souporcell.smk"  # demultiplexing + doublet detection

## DoubletDetection
doubletdetection_files = []
doubletdetection_passed = False
if "DoubletDetection" in methods:
    doubletdetection_dict = config["doubletdetection"]
    doubletdetection_manual_dict = config["doubletdetection_manual"]
    doubletdetection_extra_dict = config["doubletdetection_extra"]

    if not isinstance(doubletdetection_manual_dict["run_doubletdetection_manual"], bool):
        logger.info("\nERROR: the 'run_doubletdetection_manual' variable in the configuration file is not a boolean. Please use True or False.\n\n Exiting.")
        exit()

    doubletdetection_man_select_path = os.path.join(output_dict["output_dir"], "manual_selections", "DoubletDetection_manual_selection.tsv")
    if not os.path.isdir(os.path.join(output_dict["output_dir"], "manual_selections")):
        os.mkdir(os.path.join(output_dict["output_dir"], "manual_selections"))
    empty_doubletdetection_selection = pd.DataFrame({"Pool": samples_df["Pool"], "Result": "TBD"})
    if os.path.exists(doubletdetection_man_select_path):
        # Run DoubletDetection based on the manual selection file.
        logger.info("Read in the DoubletDetection manual selection file.")
        doubletdetection_selection = pd.read_csv(doubletdetection_man_select_path, sep="\t")
        doubletdetection_selection["Pool"] = doubletdetection_selection["Pool"].astype(str)
        doubletdetection_selection["Result"] = doubletdetection_selection["Result"].astype(str)

        # Check if something has been filled in.
        if not doubletdetection_selection.equals(empty_doubletdetection_selection):
            # Check if the pools still match.
            if len(set(samples_df["Pool"]).intersection(set(doubletdetection_selection["Pool"]))) != n_pools:
                logger.info("ERROR: the DoubletDetection_manual_selection.tsv does not contain the same pools as the samplesheet.")
                exit()

            if "PASS" in doubletdetection_selection and doubletdetection_selection["Result"].value_counts()["PASS"] == n_pools:
                logger.info("All the DoubletDetection results have PASSED. Will move to next steps.")
                # doubletdetection_files = [os.path.join(output_dict["output_dir"], pool, "DoubletDetection", "DoubletDetection_doublets_singlets.tsv") for pool in samples_df["Pool"]]
                doubletdetection_passed = True
                for pool in samples_df["Pool"]:
                    combine_results_extra_dict["combine_results_files"][pool]["DoubletDetection"] = os.path.join(output_dict["output_dir"], pool, "DoubletDetection", "DoubletDetection_doublets_singlets.tsv")
            else:
                logger.info("You haven't put PASS/FAIL values into the DoubletDetection_manual_selection.tsv file.")
                logger.info("Please check the DoubletDetection outputs and decide if the pools passed - rerun any of the pools where the doublet numbers don't reach convergence using the manual selections (see the docs).")
                logger.info("Once you are happy with the results, input PASS into the second column of the DoubletDetection_manual_selection.tsv file and restart the snakemake pipeline.")
    else:
        # Save the manual selection file.
        empty_doubletdetection_selection.to_csv(doubletdetection_man_select_path, sep="\t", index=False)

    if not doubletdetection_passed:
        # Run DoubletDetection jobs.
        if doubletdetection_manual_dict["run_doubletdetection_manual"]:
            logger.info("Running DoubletDetection for specified rules since 'run_doubletdetection_manual' is set to True.")
            doubletdetection_files = [os.path.join(output_dict["output_dir"], pool, "DoubletDetection", "DoubletDetection_doublets_singlets.tsv") for pool in doubletdetection_manual_dict["DoubletDetection_manual_pools"]]
            # TODO this will fail if you do multiple manual runs (e.g. checking if DoubletDetection_doublets_singlets.tsv exists). Therefore remove the results file to force a rerun.
            for fname in doubletdetection_files:
                if os.path.isfile(fname):
                    os.remove(fname)
            doubletdetection_params_dict = {
                "log": "manual_rerun_variables.txt",
                "step": "manual",
                "n_iterations": {pool: doublet_threshold for pool, doublet_threshold in zip(doubletdetection_manual_dict["doubletdetection_manual_pools"], doubletdetection_manual_dict["doubletdetection_manual_n_iterations"])},
                "phenograph": {pool: doublet_threshold for pool, doublet_threshold in zip(doubletdetection_manual_dict["doubletdetection_manual_pools"], doubletdetection_manual_dict["doubletdetection_manual_phenograph"])},
                "standard_scaling": {pool: doublet_threshold for pool, doublet_threshold in zip(doubletdetection_manual_dict["doubletdetection_manual_pools"], doubletdetection_manual_dict["doubletdetection_manual_standard_scaling"])},
                "p_thresh": {pool: doublet_threshold for pool, doublet_threshold in zip(doubletdetection_manual_dict["doubletdetection_manual_pools"], doubletdetection_manual_dict["doubletdetection_manual_p_thresh"])},
                "voter_thresh": {pool: doublet_threshold for pool, doublet_threshold in zip(doubletdetection_manual_dict["doubletdetection_manual_pools"], doubletdetection_manual_dict["doubletdetection_manual_voter_thresh"])}
            }
        else:
            logger.info("Running the default DoubletDetection rules since 'run_doubletdetection_manual' is set to False.")
            doubletdetection_files = [os.path.join(output_dict["output_dir"], pool, "DoubletDetection", "DoubletDetection_doublets_singlets.tsv") for pool in samples_df["Pool"]]
            doubletdetection_params_dict = {
                "log": "default_run_variables.txt",
                "step": "default",
                "n_iterations": {pool: doubletdetection_extra_dict["n_iterations"] for pool in samples_df["Pool"]},
                "phenograph": {pool: doubletdetection_extra_dict["phenograph"] for pool in samples_df["Pool"]},
                "standard_scaling": {pool: doubletdetection_extra_dict["standard_scaling"] for pool in samples_df["Pool"]},
                "p_thresh": {pool: doubletdetection_extra_dict["p_thresh"] for pool in samples_df["Pool"]},
                "voter_thresh": {pool: doubletdetection_extra_dict["voter_thresh"] for pool in samples_df["Pool"]}
            }

    include: "includes/Snakefile_DoubletDetection.smk"  # doublet detection

# DoubletFinder
# doubletfinder_files = []
if "DoubletFinder" in methods:
    doubletfinder_dict = config["doubletfinder"]
    doubletfinder_extra_dict = config["doubletfinder_extra"]

    # doubletfinder_files = [os.path.join(output_dict["output_dir"], pool, "DoubletFinder", "DoubletFinder_doublets_singlets.tsv") for pool in samples_df["Pool"]]
    for pool in samples_df["Pool"]:
        combine_results_extra_dict["combine_results_files"][pool]["DoubletFinder"] = os.path.join(output_dict["output_dir"], pool, "DoubletFinder", "DoubletFinder_doublets_singlets.tsv")
    include: "includes/Snakefile_DoubletFinder.smk"  # doublet detection

# scDblFinder
# scdblfinder_files = []
if "scDblFinder" in methods:
    scdblfinder_dict = config["scdblfinder"]

    # scdblfinder_files = [os.path.join(output_dict["output_dir"], pool, "scDblFinder", "scDblFinder_doublets_singlets.tsv") for pool in samples_df["Pool"]]
    for pool in samples_df["Pool"]:
        combine_results_extra_dict["combine_results_files"][pool]["scDblFinder"] = os.path.join(output_dict["output_dir"], pool, "scDblFinder", "scDblFinder_doublets_singlets.tsv")
    include: "includes/Snakefile_scDblFinder.smk"  # doublet detection

# scds
# scds_files = []
if "scds" in methods:
    scds_dict = config["scds"]

    # scds_files = [os.path.join(output_dict["output_dir"], pool, "scds", "scds_doublets_singlets.tsv") for pool in samples_df["Pool"]]
    for pool in samples_df["Pool"]:
        combine_results_extra_dict["combine_results_files"][pool]["scds"] = os.path.join(output_dict["output_dir"], pool, "scds", "scds_doublets_singlets.tsv")
    include: "includes/Snakefile_scds.smk"  # doublet detection

## Scrublet
scrublet_files = []
scrublet_passed = False
combine_results_extra_dict["scrublet_select_dict"] = {}
if "Scrublet" in methods:
    scrublet_dict = config["scrublet"]
    scrublet_manual_dict = config["scrublet_manual"]
    scrublet_extra_dict = config["scrublet_extra"]

    if not isinstance(scrublet_manual_dict["run_scrublet_manual"], bool):
        logger.info("\nERROR: the 'run_scrublet_manual' variable in the configuration file is not a boolean. Please use True or False.\n\n Exiting.")
        exit()

    ## the scrublet files that will be run are dependent on user inputs in the yaml file
    scrublet_per_man_select_path = os.path.join(output_dict["output_dir"], "manual_selections", "Scrublet_percentile_manual_selection.tsv")
    if not os.path.isdir(os.path.join(output_dict["output_dir"], "manual_selections")):
        os.mkdir(os.path.join(output_dict["output_dir"], "manual_selections"))
    scrublet_select_dict = {}
    empty_scrublet_selection = pd.DataFrame({"Pool": samples_df["Pool"], "GeneVariabilityPctl": "TBD"})
    if os.path.exists(scrublet_per_man_select_path):
        # Run scrublet based on the manual selection file.
        logger.info("Read in the Scrublet manual selection file.")
        scrublet_selection = pd.read_csv(scrublet_per_man_select_path, sep="\t")
        scrublet_selection["Pool"] = scrublet_selection["Pool"].astype(str)
        scrublet_selection["GeneVariabilityPctl"] = scrublet_selection["GeneVariabilityPctl"].astype(str)

        # Check if something has been filled in.
        if not scrublet_selection.equals(empty_scrublet_selection):
            # Check if the pools still match.
            if len(set(samples_df["Pool"]).intersection(set(scrublet_selection["Pool"]))) != n_pools:
                logger.info("ERROR: the Scrublet_percentile_manual_selection.tsv file does not contain the same pools as the sample sheet.")
                exit()

            # Check if all the percentages were filled in.
            for _, row in scrublet_selection.iterrows():
                # check if scrublet_percentile is an integer.
                if not row["GeneVariabilityPctl"].isdigit():
                    logger.info("ERROR: the 'GeneVariabilityPctl' column for pool '{}' in the Scrublet_percentile_manual_selection.tsv file contains an unexpected value.".format(row["Pool"]))
                    logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                    logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                    exit()

                # check if scrublet_percentile is between 0 and 100.
                if int(row["GeneVariabilityPctl"]) < 0 or row["GeneVariabilityPctl"] > 100:
                    logger.info("ERROR: the 'GeneVariabilityPctl' column for pool '{}' in the Scrublet_percentile_manual_selection.tsv file is not between 0 and 100.".format(row["Pool"]))
                    logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                    logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                    exit()

                # check if the scrublet_percentile exists.
                if not os.path.exists(os.path.join(output_dict["output_dir"], row["Pool"], "Scrublet_" + row["GeneVariabilityPctl"] + "Scrublet_doublets_singlets.tsv")):
                    logger.info("ERROR: the '{}/Scrublet_{}/Scrublet_doublets_singlets.tsv' does not exist.".format(row["Pool"], row["GeneVariabilityPctl"]))
                    logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                    logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                    exit()

            # All the selections are correct and the output files exist.
            logger.info("All the Scrublet results have been selected. Will move to next steps.")
            # scrublet_files = [os.path.join(output_dict["output_dir"], row["Pool"], "Scrublet_" + row["GeneVariabilityPctl"], "Scrublet_doublets_singlets.tsv") for _, row in scrublet_selection]
            scrublet_select_dict = {row["Pool"]: row["GeneVariabilityPctl"] for _, row in scrublet_selection.iterrows()}
            scrublet_passed = True
            for _, row in scrublet_selection:
                combine_results_extra_dict["combine_results_files"][row["Pool"]]["Scrublet"] = os.path.join(output_dict["output_dir"], row["Pool"], "Scrublet_" + row["GeneVariabilityPctl"], "Scrublet_doublets_singlets.tsv")
    else:
        # Save the manual selection file.
        empty_scrublet_selection.to_csv(scrublet_per_man_select_path, sep="\t", index=False)


    if not scrublet_passed:
        # Run scrublet jobs.
        if scrublet_manual_dict["run_scrublet_manual"]:
            logger.info("Running scrublet rules with manual selections since 'run_Scrublet_manual' is set to True.")
            scrublet_files = [os.path.join(output_dict["output_dir"], pool, "Scrublet_" + str(pctl), "Scrublet_doublets_singlets.tsv") for pool in scrublet_manual_dict["scrublet_manual_threshold_pools"] for pctl in scrublet_manual_dict["scrublet_manual_threshold_percentiles"]]
            scrublet_params_dict = {
                "step": "manual",
                "scrublet_doublet_threshold": {pool: doublet_threshold for pool, doublet_threshold in zip(scrublet_manual_dict["scrublet_manual_threshold_pools"], scrublet_manual_dict["scrublet_manual_threshold_thresholds"])}
            }
        else:
            logger.info("Running the default Scrublet rules since 'run_scrublet_manual' is set to False.")
            scrublet_files = [os.path.join(output_dict["output_dir"], pool, "Scrublet_" + str(pctl), "Scrublet_doublets_singlets.tsv") for pool in samples_df["Pool"] for pctl in scrublet_dict["percentile"]]
            scrublet_params_dict = {
                "step": "default",
                "scrublet_doublet_threshold": {pool: None for pool in samples_df["Pool"]}
            }

    combine_results_extra_dict["scrublet_select_dict"] = scrublet_select_dict
    include: "includes/Snakefile_Scrublet.smk"  # doublet detection

## Combined files at the end
combine_results_files = []
if ("DoubletDetection" not in methods or doubletdetection_passed) and ("Scrublet" not in methods or scrublet_passed):
    combine_results_files = [os.path.join(output_dict["output_dir"], pool, "CombinedResults", "combined_results_demultiplexing_summary.tsv") for pool in samples_df["Pool"]]
    include: "includes/Snakefile_CombineResults.smk"

# print("demuxlet: " + ",".join(demuxlet_files))
# print("souporcell: " + ",".join(souporcell_files))
# print("souporcell_assignments: " + ",".join(souporcell_assignments_files))
# print("DoubletDetection: " + ",".join(doubletdetection_files))
# print("DoubletFinder: " + ",".join(doubletfinder_files))
# print("scDblFinder: " + ",".join(scdblfinder_files))
# print("scds: " + ",".join(scds_files))
# print("Scrublet: " + ",".join(scrublet_files))
# print("combine_results: " + ",".join(combine_results_files))

for pool, files in combine_results_extra_dict["combine_results_files"].items():
    print(pool, files)

# Main rule - input will be all files generated at the top
rule all:
    input:
        # demuxlet_files,
        # souporcell_files,
        # souporcell_assignments_files,
        doubletdetection_files,
        # doubletfinder_files,
        # scdblfinder_files,
        # scds_files,
        scrublet_files,
        combine_results_files