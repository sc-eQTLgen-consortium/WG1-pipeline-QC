#!/usr/bin/env python
import pandas as pd
import os

# Get the samples.
SAMPLES = pd.read_csv(config["inputs"]["samplesheet_filepath"], sep="\t")
SAMPLES = SAMPLES.iloc[:1, :] #TODO: remove
SAMPLES.columns = ["Pool", "N"]
SAMPLES["Pool"] = SAMPLES["Pool"].astype(str)
SAMPLES_DICT = dict(zip(SAMPLES["Pool"], SAMPLES["N"]))

# Find which methods to run.
METHODS = []
if config["settings"]["is_multiplexed"]:
    METHODS.extend(config["settings_extra"]["multiplexing_methods"])
if config["settings"]["sc_data_type"] == "single-cell":
    METHODS.extend(config["settings_extra"]["sc_doubletdetection_methods"])
elif config["settings"]["sc_data_type"] == "single-nucleus":
    METHODS.extend(config["settings_extra"]["sn_doubletdetection_methods"])
else:
    logger.info("\nERROR: the 'sc_data_type' variable in the configuration file is not recognised. Please use 'single-cell' or 'single-nucleus'.\n\n Exiting.")
    quit()

# Remove trailing /.
if not config["inputs"]["sc_rnaseq_dir"].endswith("/"):
    config["inputs"]["sc_rnaseq_dir"] += "/"
if not config["inputs"]["individual_list_dir"].endswith("/"):
    config["inputs"]["individual_list_dir"] += "/"
if not config["outputs"]["output_dir"].endswith("/"):
    config["outputs"]["output_dir"] += "/"
if not config["outputs"]["output_dir"].endswith("/"):
    config["outputs"]["output_dir"] += "/"

if not config["refs_extra"]["relative_fasta_path"].startswith("/"):
    config["refs_extra"]["relative_fasta_path"] = "/" + config["refs_extra"]["relative_fasta_path"]
if not config["settings_extra"]["relative_barcodes_path"].startswith("/"):
    config["settings_extra"]["relative_barcodes_path"] = "/" + config["settings_extra"]["relative_barcodes_path"]
if not config["settings_extra"]["relative_filtered_h5_path"].startswith("/"):
    config["settings_extra"]["relative_filtered_h5_path"] = "/" + config["settings_extra"]["relative_filtered_h5_path"]
if not config["settings_extra"]["relative_bam_path"].startswith("/"):
    config["settings_extra"]["relative_bam_path"] = "/" + config["settings_extra"]["relative_bam_path"]

#####################
######## ALL ########
#####################
def get_all_input(wildcards):
    """
    This function determines all files that are required for the current run. This has to be dynamic since DoubletDetection and Scrublet require
    a manual selection step. Simply requesting the final files is not an option since we do not know if the runs possed or not. Therefore,
    we create a list of all method output files that we require. However, if DoubletDetection or Scrublet are not run or if the manual_selection says
    they passed we can skip over all this and directory request the combined_results output.
    """
    input_files = []

    if "popscle" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/popscle/demuxlet/demuxletOUT.best", pool=SAMPLES["Pool"]))

    if "souporcell" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/souporcell/clusters.tsv", pool=SAMPLES["Pool"]))
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/souporcell/genotype_correlations/Genotype_ID_key.txt", pool=SAMPLES["Pool"]))

    if "DoubletFinder" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/DoubletFinder/DoubletFinder_doublets_singlets.tsv", pool=SAMPLES["Pool"]))

    if "scDblFinder" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/scDblFinder/scDblFinder_doublets_singlets.tsv", pool=SAMPLES["Pool"]))

    doubletdetection_passed = False
    if "DoubletDetection" in METHODS:
        if not os.path.isdir(config["outputs"]["output_dir"] + "manual_selections"):
            os.mkdir(config["outputs"]["output_dir"] + "manual_selections")

        man_select_path = config["outputs"]["output_dir"] + "manual_selections/DoubletDetection_manual_selection.tsv"
        if os.path.exists(man_select_path):
            # Find which thresholds were selected.
            logger.info("Read in the DoubletDetection manual selection file.")
            selection = pd.read_csv(man_select_path,sep="\t")
            selection["Pool"] = selection["Pool"].astype(str)
            selection["Result"] = selection["Result"].astype(str)

            # Check if the pools still match.
            if len(set(SAMPLES["Pool"]).intersection(set(selection["Pool"]))) != SAMPLES.shape[0]:
                logger.info("ERROR: the DoubletDetection_manual_selection.tsv does not contain the same pools as the samplesheet.")
                exit()

            if "PASS" in selection and selection["Result"].value_counts()["PASS"] == SAMPLES.shape[0]:
                logger.info("All the DoubletDetection results have PASSED. Will move to next steps.")
                doubletdetection_passed = True
            else:
                logger.info("You haven't put PASS/FAIL values into the DoubletDetection_manual_selection.tsv file.")
                logger.info("Please check the DoubletDetection outputs and decide if the pools passed - rerun any of the pools where the doublet numbers don't reach convergence using the manual selections (see the docs).")
                logger.info("Once you are happy with the results, input PASS into the second column of the DoubletDetection_manual_selection.tsv file and restart the snakemake pipeline.")

        if not doubletdetection_passed:
            # Run DoubletDetection jobs.
            doubletdetection_files = []
            if config["doubletdetection_manual"]["run_doubletdetection_manual"]:
                logger.info("Running DoubletDetection for specified rules since 'run_doubletdetection_manual' is set to True.")
                doubletdetection_files = [os.path.join(config["outputs"]["output_dir"],pool,"DoubletDetection","DoubletDetection_doublets_singlets.tsv") for pool in config["doubletdetection_manual"]["DoubletDetection_manual_pools"]]
                # TODO this will fail if you do multiple manual runs (e.g. checking if DoubletDetection_doublets_singlets.tsv exists). Therefore remove the results file to force a rerun.
                for fname in doubletdetection_files:
                    if os.path.isfile(fname):
                        os.remove(fname)
            else:
                logger.info("Running the default DoubletDetection rules since 'run_doubletdetection_manual' is set to False.")
                doubletdetection_files = [os.path.join(config["outputs"]["output_dir"],pool,"DoubletDetection","DoubletDetection_doublets_singlets.tsv") for pool in SAMPLES["Pool"]]
            input_files.extend(doubletdetection_files)

    if "scds" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/scds/scds_doublets_singlets.tsv", pool=SAMPLES["Pool"]))

    scrublet_passed = False
    if "Scrublet" in METHODS:
        if not os.path.isdir(config["outputs"]["output_dir"] + "manual_selections"):
            os.mkdir(config["outputs"]["output_dir"] + "manual_selections")

        man_select_path = config["outputs"]["output_dir"] + "manual_selections/Scrublet_percentile_manual_selection.tsv"
        if os.path.exists(man_select_path):
            # Find which thresholds were selected.
            logger.info("Read in the Scrublet manual selection file.")
            selection = pd.read_csv(man_select_path,sep="\t")
            selection["Pool"] = selection["Pool"].astype(str)
            selection["GeneVariabilityPctl"] = selection["GeneVariabilityPctl"].astype(str)
            select_dict = dict(zip(selection["Pool"], selection["GeneVariabilityPctl"]))

            # Check if the pools still match.
            if len(set(SAMPLES["Pool"]).intersection(set(selection["Pool"]))) != SAMPLES.shape[0]:
                logger.info("ERROR: the Scrublet_percentile_manual_selection.tsv file does not contain the same pools as the sample sheet.")
                exit()

            # Check if all the percentages were filled in.
            for _, row in selection.iterrows():
                # check if scrublet_percentile is an integer.
                if not row["GeneVariabilityPctl"].isdigit():
                    logger.info("ERROR: the 'GeneVariabilityPctl' column for pool '{}' in the Scrublet_percentile_manual_selection.tsv file contains an unexpected value.".format(row["Pool"]))
                    logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                    logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                    exit()

                # check if scrublet_percentile is between 0 and 100.
                if int(row["GeneVariabilityPctl"]) < 0 or row["GeneVariabilityPctl"] > 100:
                    logger.info("ERROR: the 'GeneVariabilityPctl' column for pool '{}' in the Scrublet_percentile_manual_selection.tsv file is not between 0 and 100.".format(row["Pool"]))
                    logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                    logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                    exit()

                # check if the scrublet_percentile exists.
                if not os.path.exists(os.path.join(config["outputs"]["output_dir"], row["Pool"], "Scrublet_" + row["GeneVariabilityPctl"] + "Scrublet_doublets_singlets.tsv")):
                    logger.info("ERROR: the '{}/Scrublet_{}/Scrublet_doublets_singlets.tsv' does not exist.".format(row["Pool"], row["GeneVariabilityPctl"]))
                    logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                    logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                    exit()

            # All the selections are correct and the output files exist.
            logger.info("All the Scrublet results have been selected. Will move to next steps.")
            scrublet_passed = True

        if not scrublet_passed:
            # Run scrublet jobs.
            scrublet_files = []
            if config["scrublet_manual"]["run_scrublet_manual"]:
                logger.info("Running scrublet rules with manual selections since 'run_Scrublet_manual' is set to True.")
                scrublet_files = [os.path.join(config["outputs"]["output_dir"],pool,"Scrublet_" + str(pctl),"Scrublet_doublets_singlets.tsv") for pool in config["scrublet_manual"]["scrublet_manual_threshold_pools"] for pctl in config["scrublet_manual"]["scrublet_manual_threshold_percentiles"]]
            else:
                logger.info("Running the default Scrublet rules since 'run_scrublet_manual' is set to False.")
                scrublet_files = [os.path.join(config["outputs"]["output_dir"],pool,"Scrublet_" + str(pctl),"Scrublet_doublets_singlets.tsv") for pool in SAMPLES["Pool"] for pctl in config["scrublet"]["percentile"]]
            input_files.extend(scrublet_files)

    if ("DoubletDetection" not in METHODS or doubletdetection_passed) and ("Scrublet" not in METHODS or scrublet_passed):
        return expand(config["outputs"]["output_dir"] + "{pool}/CombinedResults/combined_results_demultiplexing_summary.tsv", pool=SAMPLES["Pool"])

    return input_files


rule all:
    input:
        combine_results = get_all_input


###################################
############# POPSCLE #############
###################################
rule popscle_bam_filter:
    input:
        barcodes = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_barcodes_path"],
        vcf = config["inputs"]["vcf"],
        bam = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_bam_path"],
    output:
        bam = config["outputs"]["output_dir"] + "{pool}/popscle/bam_filter/{pool}_snpfiltered_alignment.bam"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["popscle"]["popscle_bam_filter_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["popscle"]["popscle_bam_filter_memory"]
    threads: config["popscle"]["popscle_bam_filter_threads"]
    params:
        out_dir = config["outputs"]["output_dir"] + "{pool}/popscle/bam_filter/",
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        tag_group = config["popscle"]["popscle_tag_group"]
    log: config["outputs"]["output_dir"] + "logs/popscle_bam_filter.{pool}.log"
    shell:
        """
        mkdir -p {params.out_dir} && \
        singularity exec --bind {params.bind} {params.sif} bedtools merge \
            -i {input.vcf} | singularity exec \
                --bind {params.bind} {params.sif} samtools view \
                    --target-file \
                    - \
                    --tag-file {params.tag_group}:<(zcat {input.barcodes}) \
                    --output {output.bam} \
                    --write-index \
                    --threads {threads} \
                    {input.bam}
        """


rule popscle_pileup:
    input:
        bam = config["outputs"]["output_dir"] + "{pool}/popscle/bam_filter/{pool}_snpfiltered_alignment.bam",
        sm_list = config["inputs"]["individual_list_dir"] + "/{pool}.txt",
        vcf = config["inputs"]["vcf"],
        barcodes = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_barcodes_path"],
    output:
        pileup = config["outputs"]["output_dir"] + "{pool}/popscle/pileup/pileup.var.gz",
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["popscle"]["popscle_pileup_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["popscle"]["popscle_pileup_memory"]
    threads: config["popscle"]["popscle_pileup_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        tag_group = config["popscle"]["popscle_tag_group"],
        tag_UMI = config["popscle"]["popscle_tag_UMI"],
        cap_bq = config["popscle_extra"]["cap_bq"],
        min_bq = config["popscle_extra"]["min_bq"],
        min_mq = config["popscle_extra"]["min_mq"],
        min_td = config["popscle_extra"]["min_td"],
        excl_flag = config["popscle_extra"]["excl_flag"],
        min_total = config["popscle_extra"]["min_total"],
        min_snp = config["popscle_extra"]["min_snp"],
        out = config["outputs"]["output_dir"] + "{pool}/popscle/pileup/pileup",
    log: config["outputs"]["output_dir"] + "logs/popscle_pileup.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} popscle dsc-pileup \
            --sam {input.bam} \
            --tag-group {params.tag_group} \
            --tag-UMI {params.tag_UMI} \
            --sm-list {input.sm_list} \
            --vcf {input.vcf} \
            --cap-BQ {params.cap_bq} \
            --min-BQ {params.min_bq} \
            --min-MQ {params.min_mq} \
            --min-TD {params.min_td} \
            --excl-flag {params.excl_flag} \
            --group-list {input.barcodes} \
            --min-total {params.min_total} \
            --min-snp {params.min_snp} \
            --out {params.out}
        """


rule popscle_demuxlet:
    input:
        pileup = config["outputs"]["output_dir"] + "{pool}/popscle/pileup/pileup.var.gz",
        vcf = config["inputs"]["vcf"],
        group_list = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_barcodes_path"],
        sm_list = config["inputs"]["individual_list_dir"] + "/{pool}.txt"
    output:
        out = config["outputs"]["output_dir"] + "{pool}/popscle/demuxlet/demuxletOUT.best"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["popscle"]["popscle_demuxlet_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["popscle"]["popscle_demuxlet_memory"]
    threads: config["popscle"]["popscle_demuxlet_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        plp = config["outputs"]["output_dir"] + "{pool}/popscle/pileup/pileup",
        field = config["popscle"]["popscle_genotype_field"],
        geno_error_offset = config["popscle_extra"]["geno_error_offset"],
        geno_error_coeff = config["popscle_extra"]["geno_error_coeff"],
        r2_info = config["popscle_extra"]["r2_info"],
        min_mac = config["popscle_extra"]["min_mac"],
        min_callrate = config["popscle_extra"]["min_callrate"],
        doublet_prior = config["popscle_extra"]["doublet_prior"],
        cap_bq = config["popscle_extra"]["cap_bq"],
        min_bq = config["popscle_extra"]["min_bq"],
        min_mq = config["popscle_extra"]["min_mq"],
        min_td = config["popscle_extra"]["min_td"],
        excl_flag = config["popscle_extra"]["excl_flag"],
        min_total = config["popscle_extra"]["min_total"],
        min_snp = config["popscle_extra"]["min_snp"],
        out = config["outputs"]["output_dir"] + "{pool}/popscle/demuxlet/demuxletOUT"
    log: config["outputs"]["output_dir"] + "logs/popscle_demuxlet.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} popscle demuxlet \
            --plp {params.plp} \
            --vcf {input.vcf} \
            --field {params.field} \
            --geno-error-offset {params.geno_error_offset} \
            --geno-error-coeff {params.geno_error_coeff} \
            --r2-info {params.r2_info} \
            --min-mac {params.min_mac} \
            --min-callrate {params.min_callrate} \
            --group-list {input.group_list} \
            --sm-list {input.sm_list} \
            --doublet-prior {params.doublet_prior} \
            --cap-BQ {params.cap_bq} \
            --min-BQ {params.min_bq} \
            --min-MQ {params.min_mq} \
            --min-TD {params.min_td} \
            --excl-flag {params.excl_flag} \
            --min-total {params.min_total} \
            --min-snp {params.min_snp} \
            --out {params.out}
        [[ -s {output.out} ]]
        echo $?
        """

####################################
############ SOUPORCELL ############
####################################
rule souporcell:
    input:
        bam = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_bam_path"],
        barcodes = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_barcodes_path"],
        fasta = config["refs"]["ref_dir"] + config["refs_extra"]["relative_fasta_path"],
        vcf = config["inputs"]["vcf"]
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["souporcell"]["souporcell_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["souporcell"]["souporcell_memory"]
    threads: config["souporcell"]["souporcell_threads"]
    output:
        ambient_rna = config["outputs"]["output_dir"] + "{pool}/souporcell/ambient_rna.txt",
        clustering = config["outputs"]["output_dir"] + "{pool}/souporcell/clustering.done",
        genotypes = config["outputs"]["output_dir"] + "{pool}/souporcell/cluster_genotypes.vcf",
        clusters = config["outputs"]["output_dir"] + "{pool}/souporcell/clusters.tsv",
        concensus = config["outputs"]["output_dir"] + "{pool}/souporcell/consensus.done",
        troublet = config["outputs"]["output_dir"] + "{pool}/souporcell/troublet.done"
    params:
        out = config["outputs"]["output_dir"] + "{pool}/souporcell/",
        sif = config["inputs"]["singularity_image"],
        bind = config["inputs"]["bind_path"],
        clusters = lambda wildcards: SAMPLES_DICT[wildcards.pool],
        min_alt = config["souporcell_extra"]["min_alt"],
        min_ref = config["souporcell_extra"]["min_ref"],
        max_loci = config["souporcell_extra"]["max_loci"]
    log: config["outputs"]["output_dir"] + "logs/souporcell.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} souporcell_pipeline.py \
            --bam {input.bam} \
            --barcodes {input.barcodes} \
            --fasta {input.fasta} \
            --threads {threads} \
            --out_dir {params.out} \
            --clusters {params.clusters} \
            --common_variants {input.vcf} \
            --min_alt {params.min_alt} \
            --min_ref {params.min_ref} \
            --max_loci {params.max_loci} 2> {log}
        [[ -s {output.genotypes} ]]
        echo $?
        """


rule souporcell_summary:
    input:
        clusters = config["outputs"]["output_dir"] + "{pool}/souporcell/clusters.tsv"
    output:
        summary = config["outputs"]["output_dir"] + "{pool}/souporcell/souporcell_summary.tsv"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["souporcell"]["souporcell_summary_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["souporcell"]["souporcell_summary_memory"]
    threads: config["souporcell"]["souporcell_summary_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"]
    log: config["outputs"]["output_dir"] + "logs/souporcell_summary.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} \
            awk 'BEGIN{FS=OFS="\t"} $2=="unassigned" {$3="unassigned"}1' $1 \
            | awk 'BEGIN{FS=OFS="\t"}{print $3}' \
            | sed -E 's|[0-9]+/[0-9]+|doublet|g' \
            | tail -n+2 \
            | sort \
            | uniq -c \
            | sed -E 's/^ +//g' \
            | sed 's/ /\t/g' \
            | sed '1 i\Assignment N\tClassification' \
            | awk 'BEGIN{FS=OFS="\t"}{print($2,$1)}' {input.clusters} > {output.summary}
        """


rule souporcell_pool_vcf:
    input:
        vcf = config["inputs"]["vcf"],
        cluster_vcf = config["outputs"]["output_dir"] + "{pool}/souporcell/cluster_genotypes.vcf"
    output:
        filtered_refs_temp = config["outputs"]["output_dir"] + "{pool}/souporcell/Individual_genotypes_subset.vcf",
        filtered_refs = config["outputs"]["output_dir"] + "{pool}/souporcell/Individual_genotypes_subset.vcf.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["souporcell"]["souporcell_pool_vcf_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["souporcell"]["souporcell_pool_vcf_memory"]
    threads: config["souporcell"]["souporcell_pool_vcf_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        individuals = config["inputs"]["individual_list_dir"] + "/{pool}.txt"
    log: config["outputs"]["output_dir"] + "logs/souporcell_pool_vcf.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} bedtools intersect -a {input.vcf} -b {input.cluster_vcf} -f 1.0 -r -wa -header > {output.filtered_refs_temp} 2> {log}
        singularity exec --bind {params.bind} {params.sif} bcftools view -S {params.individuals} -Oz -o {output.filtered_refs} {output.filtered_refs_temp} 2>> {log}
        """


rule souporcell_correlate_genotypes:
    input:
        reference_vcf = config["outputs"]["output_dir"] + "{pool}/souporcell/Individual_genotypes_subset.vcf.gz",
        cluster_vcf = config["outputs"]["output_dir"] + "{pool}/souporcell/cluster_genotypes.vcf",
    output:
        correlation_file = config["outputs"]["output_dir"] + "{pool}/souporcell/genotype_correlations/ref_clust_pearson_correlations.tsv",
        correlation_img = config["outputs"]["output_dir"] + "{pool}/souporcell/genotype_correlations/ref_clust_pearson_correlation.png",
        assignments = config["outputs"]["output_dir"] + "{pool}/souporcell/genotype_correlations/Genotype_ID_key.txt"
    resources:
        mem_per_thread_gb = config["souporcell"]["souporcell_correlations_memory"],
        disk_per_thread_gb = config["souporcell"]["souporcell_correlations_memory"]
    threads: config["souporcell"]["souporcell_correlations_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/Assign_Indiv_by_Geno.R",
        out = config["outputs"]["output_dir"] + "{pool}/souporcell/genotype_correlations"
    log: config["outputs"]["output_dir"] + "logs/souporcell_correlate_genotypes.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} Rscript {params.script}
            --reference_vcf {input.reference_vcf} \
            --cluster_vcf {input.cluster_vcf} \
            --out {params.out} \
            2> {log}
        [[ -s {output.assignments} ]]
        echo $?
        """

#####################################
############ DoubletFinder ##########
#####################################
rule DoubletFinder:
    input:
        counts = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_filtered_h5_path"],
    output:
        doublets = config["outputs"]["output_dir"] + "{pool}/DoubletFinder/DoubletFinder_doublets_singlets.tsv",
        summary = config["outputs"]["output_dir"] + "{pool}/DoubletFinder/DoubletFinder_doublet_summary.tsv"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["doubletfinder"]["doubletfinder_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["doubletfinder"]["doubletfinder_memory"]
    threads: config["doubletfinder"]["doubletfinder_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/DoubletFinder.R",
        out = config["outputs"]["output_dir"] + "{pool}/DoubletFinder/",
        find_clusters_resolution = config["doubletfinder_extra"]["find_clusters_resolution"],
        n_generated_artificial_doublets = config["doubletfinder_extra"]["n_generated_artificial_doublets"]
    log: config["outputs"]["output_dir"] + "logs/DoubletFinder.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} Rscript {params.script} \
            --out {params.out} \
            --counts {input.counts} \
            --resolution {params.find_clusters_resolution} \
            --pN {params.n_generated_artificial_doublets}
        """

#####################################
############ scDblFinder ############
#####################################
rule scDblFinder:
    input:
        counts = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_filtered_h5_path"],
    output:
        doublets = config["outputs"]["output_dir"] + "{pool}/scDblFinder/scDblFinder_doublets_singlets.tsv",
        summary = config["outputs"]["output_dir"] + "{pool}/scDblFinder/scDblFinder_doublet_summary.tsv"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["scdblfinder"]["scfblfinder_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["scdblfinder"]["scfblfinder_memory"]
    threads: config["scdblfinder"]["scdblfinder_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/scDblFinder.R",
        out = config["outputs"]["output_dir"] + "{pool}/scDblFinder/"
    log: config["outputs"]["output_dir"] + "logs/scDblFinder.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} Rscript {params.script} \
            --out {params.out} \
            --counts {input.counts}
        """

###########################################
############ DOUBLET DETECTION ############
###########################################
# These steps uses different settings based on the user input in the yaml.
if config["doubletdetection_manual"]["run_doubletdetection_manual"]:
    logger.info("Running DoubletDetection with manual settings since 'run_doubletdetection_manual' is set to True.")
    doubletdetection_params_dict = {
        "log": "manual_rerun_variables.txt",
        "step": "manual",
        "n_iterations": {str(pool): doublet_threshold for pool, doublet_threshold in zip(config["doubletdetection_manual"]["doubletdetection_manual_pools"],config["doubletdetection_manual"]["doubletdetection_manual_n_iterations"])},
        "phenograph": {str(pool): doublet_threshold for pool, doublet_threshold in zip(config["doubletdetection_manual"]["doubletdetection_manual_pools"],config["doubletdetection_manual"]["doubletdetection_manual_phenograph"])},
        "standard_scaling": {str(pool): doublet_threshold for pool, doublet_threshold in zip(config["doubletdetection_manual"]["doubletdetection_manual_pools"],config["doubletdetection_manual"]["doubletdetection_manual_standard_scaling"])},
        "p_thresh": {str(pool): doublet_threshold for pool, doublet_threshold in zip(config["doubletdetection_manual"]["doubletdetection_manual_pools"],config["doubletdetection_manual"]["doubletdetection_manual_p_thresh"])},
        "voter_thresh": {str(pool): doublet_threshold for pool, doublet_threshold in zip(config["doubletdetection_manual"]["doubletdetection_manual_pools"],config["doubletdetection_manual"]["doubletdetection_manual_voter_thresh"])}
    }
else:
    logger.info("RunningDoubletDetection with default settings since 'run_doubletdetection_manual' is set to False.")
    doubletdetection_params_dict = {
        "log": "default_run_variables.txt",
        "step": "default",
        "n_iterations": {pool: config["doubletdetection_extra"]["n_iterations"] for pool in SAMPLES["Pool"]},
        "phenograph": {pool: config["doubletdetection_extra"]["phenograph"] for pool in SAMPLES["Pool"]},
        "standard_scaling": {pool: config["doubletdetection_extra"]["standard_scaling"] for pool in SAMPLES["Pool"]},
        "p_thresh": {pool: config["doubletdetection_extra"]["p_thresh"] for pool in SAMPLES["Pool"]},
        "voter_thresh": {pool: config["doubletdetection_extra"]["voter_thresh"] for pool in SAMPLES["Pool"]}
    }


rule DoubletDetection:
    input:
        counts = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_filtered_h5_path"],
        barcodes = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_barcodes_path"],
    output:
        doublets = config["outputs"]["output_dir"] + "{pool}/DoubletDetection/DoubletDetection_doublets_singlets.tsv",
        figure = report(config["outputs"]["output_dir"] + "{pool}/DoubletDetection/convergence_test.pdf", category = "DoubletDetection", subcategory = "{pool}", caption = "../report_captions/DoubletDetection.rst"),
        summary = config["outputs"]["output_dir"] + "{pool}/DoubletDetection/DoubletDetection_summary.tsv",
        log = config["outputs"]["output_dir"] + "{pool}/DoubletDetection/" + doubletdetection_params_dict["log"]
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["doubletdetection"]["doubletdetection_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["doubletdetection"]["doubletdetection_memory"]
    threads: config["doubletdetection"]["doubletdetection_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/DoubletDetection.py",
        n_iterations = lambda wildcards: doubletdetection_params_dict["n_iterations"][wildcards.pool],
        phenograph = lambda wildcards: doubletdetection_params_dict["phenograph"][wildcards.pool],
        standard_scaling = lambda wildcards: doubletdetection_params_dict["standard_scaling"][wildcards.pool],
        p_thresh = lambda wildcards: doubletdetection_params_dict["p_thresh"][wildcards.pool],
        voter_thresh = lambda wildcards: doubletdetection_params_dict["voter_thresh"][wildcards.pool],
        step = doubletdetection_params_dict["step"],
        out = config["outputs"]["output_dir"] + "{pool}/DoubletDetection/"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --counts {input.counts} \
            --barcodes {input.barcodes} \
            --n_iterations {params.n_iterations} \
            --phenograph {params.phenograph} \
            --standard_scaling {params.standard_scaling} \
            --p_thresh {params.p_thresh} \
            --voter_thresh {params.voter_thresh} \
            --out {params.out} > {output.log}

		singularity exec --bind {params.bind} {params.sif} echo "The pool:" {wildcards.pool} >> {output.log}
		singularity exec --bind {params.bind} {params.sif} echo "This was a" {params.step} "run" >> {output.log}
		singularity exec --bind {params.bind} {params.sif} echo "The number of iterations used to determine doublets:" {params.n_iterations} >> {output.log}
		singularity exec --bind {params.bind} {params.sif} echo "The phenograph was was used:" {params.phenograph} >> {output.log}
		singularity exec --bind {params.bind} {params.sif} echo "The standard scaling was used:" {params.standard_scaling} >> {output.log}
		singularity exec --bind {params.bind} {params.sif} echo "The p threshold was used:" {params.p_thresh} >> {output.log}
		singularity exec --bind {params.bind} {params.sif} echo "The voter threshold is:" {params.voter_thresh} >> {output.log}
        """

##############################
############ SCDS ############
##############################
rule scds:
    input:
        counts = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_filtered_h5_path"],
    output:
        doublets = config["outputs"]["output_dir"] + "{pool}/scds/scds_doublets_singlets.tsv",
        summary = config["outputs"]["output_dir"] + "{pool}/scds/scds_doublet_summary.tsv"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["scds"]["scds_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["scds"]["scds_memory"]
    threads: config["scds"]["scds_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/scds.R",
        out = config["outputs"]["output_dir"] + "{pool}/scds/"
    log: config["outputs"]["output_dir"] + "logs/scds.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} Rscript {params.script} \
            --out {params.out} \
            --counts {input.counts}
        """

##################################
############ SCRUBLET ############
##################################
# These steps uses different settings based on the user input in the yaml.
if config["scrublet_manual"]["run_scrublet_manual"]:
    logger.info("Running Scrublet with manual settings since 'run_scrublet_manual' is set to True.")
    pool_threshold_dict = dict(zip(config["scrublet_manual"]["scrublet_manual_threshold_pools"], config["scrublet_manual"]["scrublet_manual_threshold_thresholds"]))
    scrublet_params_dict = {
        "step": "manual",
        "scrublet_doublet_threshold": {str(pool): doublet_threshold for pool, doublet_threshold in zip(config["scrublet_manual"]["scrublet_manual_threshold_pools"], config["scrublet_manual"]["scrublet_manual_threshold_thresholds"])}
    }
else:
    logger.info("Running Scrublet with default settings since 'run_scrublet_manual' is set to False.")
    scrublet_params_dict = {
        "step": "default",
        "scrublet_doublet_threshold": {pool: None for pool in SAMPLES["Pool"]}
    }

rule Scrublet:
    input:
        counts = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_filtered_h5_path"],
        barcodes = config["inputs"]["sc_rnaseq_dir"] + "{pool}" + config["settings_extra"]["relative_barcodes_path"]
    output:
        figure = report(config["outputs"]["output_dir"] + "{pool}/Scrublet_{pctl}/doublet_score_histogram.png", category = "Scrublet", caption = "../report_captions/Scrublet.rst", subcategory = "{pool}"),
        umap = report(config["outputs"]["output_dir"] + "{pool}/Scrublet_{pctl}/UMAP.png", category = "Scrublet", caption = "../report_captions/Scrublet.rst", subcategory = "{pool}"),
        results = config["outputs"]["output_dir"] + "{pool}/Scrublet_{pctl}/Scrublet_doublets_singlets.tsv",
        summary = config["outputs"]["output_dir"] + "{pool}/Scrublet_{pctl}/Scrublet_summary.tsv"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["scrublet"]["scrublet_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["scrublet"]["scrublet_memory"],
    threads: config["scrublet"]["scrublet_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/Scrublet_pipeline.py",
        sim_dbl = config["scrublet_extra"]["sim_dbl"],
        min_counts = config["scrublet_extra"]["min_counts"],
        min_cells = config["scrublet_extra"]["min_cells"],
        n_prin_comps = config["scrublet_extra"]["n_prin_comps"],
        out = config["outputs"]["output_dir"] + "{pool}/Scrublet_{pctl}/",
        step = lambda wildcards: scrublet_params_dict["step"],
        scrublet_doublet_threshold = lambda wildcards: scrublet_params_dict["scrublet_doublet_threshold"][wildcards.pool],
    log: config["outputs"]["output_dir"] + "logs/Scrublet.{pool}.pctl{pctl}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --counts {input.counts} \
            --barcodes {input.barcodes} \
            --sim_doublet_ratio {params.sim_dbl} \
            --min_counts {params.min_counts} \
            --min_cells {params.min_cells} \
            --n_prin_comps {params.n_prin_comps} \
            --min_gene_variability_pctl {wildcards.pctl} \
            --scrublet_doublet_threshold {params.scrublet_doublet_threshold}
            --out {params.out}

            singularity exec --bind {params.bind} {params.sif} echo "The pool:" {wildcards.pool} >> {log}
            singularity exec --bind {params.bind} {params.sif} echo "This was a" {params.step} "run" >> {log}
            singularity exec --bind {params.bind} {params.sif} echo "The number of doublets simulated per droplet:" {params.sim_dbl} >> {log}
            singularity exec --bind {params.bind} {params.sif} echo "The min number of counts used for filtering cells prior to PCA:" {params.min_counts} >> {log}
            singularity exec --bind {params.bind} {params.sif} echo "The number of cells for a gene to be expressed in for filtering cells prior to PCA:" {params.min_cells} >> {log}
            singularity exec --bind {params.bind} {params.sif} echo "The number of principle components used to embed the trnscriptomes prior to k-nearest-neighbor graph:" {params.n_prin_comps} >> {log}
            singularity exec --bind {params.bind} {params.sif} echo "The manual doublet threshold set:" {params.scrublet_doublet_threshold} >> {log}
        [[ -s {output.results} ]]
        echo $?
        """

#################################
######## COMBINE RESULTS ########
#################################
def get_scrublet_input(wildcards):
    """
    This function selection the correct run of Scrublet we want to use for the combine_results rule.
    """
    if "Scrublet" in METHODS:
        man_select_path = config["outputs"]["output_dir"] + "manual_selections/Scrublet_percentile_manual_selection.tsv"
        if os.path.exists(man_select_path):
            # Find which thresholds were selected.
            logger.info("Read in the Scrublet manual selection file.")
            selection = pd.read_csv(man_select_path,sep="\t")
            selection["Pool"] = selection["Pool"].astype(str)
            selection["GeneVariabilityPctl"] = selection["GeneVariabilityPctl"].astype(str)
            select_dict = dict(zip(selection["Pool"], selection["GeneVariabilityPctl"]))

            return config["outputs"]["output_dir"] + "" + wildcards.pool + "/Scrublet_" + select_dict[wildcards.pool] + "/Scrublet_doublets_singlets.tsv"
    return []

rule combine_results:
    input:
        demuxlet = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/popscle/demuxlet/demuxletOUT.best" if "popscle" in METHODS else [],
        souporcell = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/souporcell/clusters.tsv" if "souporcell" in METHODS else [],
        souporcell_assignments = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/souporcell/genotype_correlations/Genotype_ID_key.txt" if "souporcell" in METHODS else [],
        doubletfinder = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/DoubletFinder/DoubletFinder_doublets_singlets.tsv" if "DoubletFinder" in METHODS else [],
        scdblfinder = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/scDblFinder/scDblFinder_doublets_singlets.tsv" if "scDblFinder" in METHODS else [],
        doubletdetection = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/DoubletDetection/DoubletDetection_doublets_singlets.tsv" if "DoubletDetection" in METHODS else [],
        scds = lambda wildcards: config["outputs"]["output_dir"] + "" + wildcards.pool + "/scds/scds_doublets_singlets.tsv" if "scds" in METHODS else [],
        scrublet = get_scrublet_input,
    output:
        summary = config["outputs"]["output_dir"] + "{pool}/CombinedResults/combined_results_demultiplexing_summary.tsv"
    resources:
        mem_per_thread_gb=lambda wildcards, attempt: attempt * config["combine_results"]["combine_results_memory"],
        disk_per_thread_gb=lambda wildcards, attempt: attempt * config["combine_results"]["combine_results_memory"]
    threads: config["combine_results"]["combine_results_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = "/opt/WG1-pipeline-QC/Demultiplexing/scripts/Combine_Results.R",
        souporcell_correlation_limit = config["souporcell"]["souporcell_genotype_correlation_threshold"],
        out = config["outputs"]["output_dir"] + "{pool}/CombinedResults/"
    log: config["outputs"]["output_dir"] + "logs/combine_results.{pool}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} Rscript {params.script} \
            --demuxlet {input.demuxlet} \
            --souporcell {input.souporcell} \
            --souporcell_assignments {input.souporcell_assignments} \
            --souporcell_correlation_limit {params.souporcell_correlation_limit} \
            --doubletfinder {input.doubletfinder} \
            --scdblfinder {input.scdblfinder} \
            --doubletdetection {input.doubletdetection} \
            --scds {input.scds} \
            --scrublet {input.scrublet} \
            --out {params.out}
        """
