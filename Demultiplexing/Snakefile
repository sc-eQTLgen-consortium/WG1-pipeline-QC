#!/usr/bin/env python
import pandas as pd
import os

# Get the samples.
SAMPLES_DF = pd.read_csv(config["inputs"]["samplesheet_filepath"], sep="\t")
SAMPLES_DF = SAMPLES_DF.iloc[:1, :] #TODO: remove
for column in ["Pool", "N"]:
    if column not in SAMPLES_DF:
        logger.info("\nERROR: column '{}' is missing in the samplesheet_filepath.\n\n Exiting.".format(column))
        quit()
SAMPLES_DF["Pool"] = SAMPLES_DF["Pool"].astype(str)

# Get the file paths.
FILE_PATHS = pd.read_csv(config["inputs"]["sample_file_paths"], sep="\t")
FILE_PATHS = FILE_PATHS.iloc[:1, :] #TODO: remove
FILE_PATHS["Pool"] = FILE_PATHS["Pool"].astype(str)
for column in ["Pool", "Bam", "Counts", "Barcodes"]:
    if column not in FILE_PATHS:
        logger.info("\nERROR: column '{}' is missing in the sample_file_paths.\n\n Exiting.".format(column))
        quit()
for pool in SAMPLES_DF["Pool"]:
    if not pool in FILE_PATHS["Pool"].values:
        logger.info("\nERROR: pool '{}' is missing in the sample_file_paths.\n\n Exiting.".format(pool))
        quit()
for _, row in FILE_PATHS.iterrows():
    for column in ["Bam", "Counts", "Barcodes"]:
        if not os.path.exists(row[column]):
            logger.info("\nERROR: file '{}' for pool '{}' in the sample_file_paths does not exist.\n\n Exiting.".format(column, row["Pool"]))
            quit()
SAMPLES_DF = SAMPLES_DF.merge(FILE_PATHS, on="Pool", how="left")
SAMPLES = SAMPLES_DF["Pool"]
SAMPLES_DF.set_index("Pool", inplace=True)

# Find which methods to run.
METHODS = []
if config["settings"]["is_multiplexed"]:
    METHODS.extend(config["settings_extra"]["multiplexing_methods"])
if config["settings"]["sc_data_type"] == "single-cell":
    METHODS.extend(config["settings_extra"]["sc_doubletdetection_methods"])
elif config["settings"]["sc_data_type"] == "single-nucleus":
    METHODS.extend(config["settings_extra"]["sn_doubletdetection_methods"])
else:
    logger.info("\nERROR: the 'sc_data_type' variable in the configuration file is not recognised. Please use 'single-cell' or 'single-nucleus'.\n\n Exiting.")
    quit()

# Check if input vcf exists.
if "popscle" in METHODS or "souporcell" in METHODS:
    for vcf in config["inputs"]["vcf"]:
        if not os.path.exists(vcf) or not os.path.exists(vcf + ".csi"):
            logger.info("\nERROR: the VCF input file (index) does not exist.\n\n Exiting.")
            quit()

# Add trailing /.
if not config["refs"]["ref_dir"].endswith("/"):
    config["refs"]["ref_dir"] += "/"
if not config["inputs"]["individual_list_dir"].endswith("/"):
    config["inputs"]["individual_list_dir"] += "/"
if not config["outputs"]["output_dir"].endswith("/"):
    config["outputs"]["output_dir"] += "/"

#####################
######## ALL ########
#####################
def get_all_input(wildcards):
    """
    This function determines all files that are required for the current run. This has to be dynamic since DoubletDetection and Scrublet require
    a manual selection step. Simply requesting the final files is not an option since we do not know if the runs possed or not. Therefore,
    we create a list of all method output files that we require. However, if DoubletDetection or Scrublet are not run or if the manual_selection says
    they passed we can skip over all this and directory request the combined_results output.
    """
    input_files = []

    if "popscle" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "count_snps/Number_SNPs.png"))
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/popscle/demuxlet/demuxletOUT.best", pool=SAMPLES))

    if "souporcell" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "count_snps/Number_SNPs.png"))
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/souporcell/souporcell_summary.tsv", pool=SAMPLES))
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/souporcell/genotype_correlations/Genotype_ID_key.txt", pool=SAMPLES))

    if "DoubletFinder" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/DoubletFinder/DoubletFinder_doublets_singlets.tsv", pool=SAMPLES))

    if "scDblFinder" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/scDblFinder/scDblFinder_doublets_singlets.tsv", pool=SAMPLES))

    doubletdetection_passed = False
    if "DoubletDetection" in METHODS:
        if not os.path.isdir(config["outputs"]["output_dir"] + "manual_selections"):
            os.mkdir(config["outputs"]["output_dir"] + "manual_selections")

        man_select_path = config["outputs"]["output_dir"] + "manual_selections/DoubletDetection_manual_selection.tsv"
        empty_select_df = pd.DataFrame({"Pool": SAMPLES, "Result": "TBD"})
        if os.path.exists(man_select_path):
            logger.info("Read in the DoubletDetection manual selection file.")
            selection = pd.read_csv(man_select_path, sep="\t", index_col=None)
            selection["Pool"] = selection["Pool"].astype(str)
            if not selection.equals(empty_select_df):
                logger.info("The DoubletDetection_manual_selection.tsv file has been updated, evaluating if selection is valid.")
                selection["Result"] = selection["Result"].astype(str)

                # Check if the pools still match.
                if len(set(SAMPLES).intersection(set(selection["Pool"]))) != SAMPLES.shape[0]:
                    logger.info("ERROR: the DoubletDetection_manual_selection.tsv does not contain the same pools as the samplesheet.")
                    exit()

                if "PASS" in selection and selection["Result"].value_counts()["PASS"] == SAMPLES.shape[0]:
                    logger.info("All the DoubletDetection results have PASSED. Will move to next steps.")
                    doubletdetection_passed = True
                else:
                    logger.info("You haven't put PASS/FAIL values into the DoubletDetection_manual_selection.tsv file.")
                    logger.info("Please check the DoubletDetection outputs and decide if the pools passed - rerun any of the pools where the doublet numbers don't reach convergence using the manual selections (see the docs).")
                    logger.info("Once you are happy with the results, input PASS into the second column of the DoubletDetection_manual_selection.tsv file and restart the snakemake pipeline.")
        else:
            empty_select_df.to_csv(man_select_path, sep="\t", header=True, index=False)

        if not doubletdetection_passed:
            # Run DoubletDetection jobs.
            doubletdetection_files = []
            if config["doubletdetection_manual"]["run_doubletdetection_manual"]:
                logger.info("Running DoubletDetection for specified rules since 'run_doubletdetection_manual' is set to True.")
                doubletdetection_files = [config["outputs"]["output_dir"] + pool + "/DoubletDetection/DoubletDetection_doublets_singlets.tsv" for pool in config["doubletdetection_manual"]["DoubletDetection_manual_pools"]]
                # NOTE: this will fail if you do multiple manual runs (e.g. checking if DoubletDetection_doublets_singlets.tsv exists). Therefore remove the results file to force a rerun.
                for fname in doubletdetection_files:
                    if os.path.isfile(fname):
                        os.remove(fname)
            else:
                logger.info("Running the default DoubletDetection rules since 'run_doubletdetection_manual' is set to False.")
                doubletdetection_files = [config["outputs"]["output_dir"] + pool + "/DoubletDetection/DoubletDetection_doublets_singlets.tsv" for pool in SAMPLES]
            input_files.extend(doubletdetection_files)

    if "scds" in METHODS:
        input_files.extend(expand(config["outputs"]["output_dir"] + "{pool}/scds/scds_doublets_singlets.tsv", pool=SAMPLES))

    scrublet_passed = False
    if "Scrublet" in METHODS:
        if not os.path.isdir(config["outputs"]["output_dir"] + "manual_selections"):
            os.mkdir(config["outputs"]["output_dir"] + "manual_selections")

        man_select_path = config["outputs"]["output_dir"] + "manual_selections/Scrublet_percentile_manual_selection.tsv"
        empty_select_df = pd.DataFrame({"Pool": SAMPLES, "GeneVariabilityPctl": "TBD"})
        if os.path.exists(man_select_path):
            # Find which thresholds were selected.
            logger.info("Read in the Scrublet manual selection file.")
            selection = pd.read_csv(man_select_path, sep="\t", index_col=None)
            selection["Pool"] = selection["Pool"].astype(str)
            if not selection.equals(empty_select_df):
                logger.info("The Scrublet_percentile_manual_selection.tsv file has been updated, evaluating if selection is valid.")
                selection["GeneVariabilityPctl"] = selection["GeneVariabilityPctl"].astype(str)

                # Check if the pools still match.
                if len(set(SAMPLES).intersection(set(selection["Pool"]))) != SAMPLES.shape[0]:
                    logger.info("ERROR: the Scrublet_percentile_manual_selection.tsv file does not contain the same pools as the sample sheet.")
                    exit()

                # Check if all the percentages were filled in.
                for _, row in selection.iterrows():
                    # check if scrublet_percentile is an integer.
                    if not row["GeneVariabilityPctl"].isdigit():
                        logger.info("ERROR: the 'GeneVariabilityPctl' column for pool '{}' in the Scrublet_percentile_manual_selection.tsv file contains an unexpected value.".format(row["Pool"]))
                        logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                        logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                        exit()

                    # check if scrublet_percentile is between 0 and 100.
                    if int(row["GeneVariabilityPctl"]) < 0 or row["GeneVariabilityPctl"] > 100:
                        logger.info("ERROR: the 'GeneVariabilityPctl' column for pool '{}' in the Scrublet_percentile_manual_selection.tsv file is not between 0 and 100.".format(row["Pool"]))
                        logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                        logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_gene_pctl.txt file and restart the snakemake pipeline.")
                        exit()

                    # check if the scrublet_percentile exists.
                    if not os.path.exists(config["outputs"]["output_dir"] + row["Pool"] + "/Scrublet_" + row["GeneVariabilityPctl"] + "/Scrublet_doublets_singlets.tsv"):
                        logger.info("ERROR: the '{}/Scrublet_{}/Scrublet_doublets_singlets.tsv' does not exist.".format(row["Pool"], row["GeneVariabilityPctl"]))
                        logger.info("Please check the Scrublet outputs and choose the best variable genes percentile - rerun any of the pools where the thresholding failed (see the docs) to choose a manual threshold.")
                        logger.info("Once you are happy with the thresholding, input the correct gene percentiles (as numbers between 0 and 100) into the second column of the Scrublet_percentile_manual_selection.tsv file and restart the snakemake pipeline.")
                        exit()

                # All the selections are correct and the output files exist.
                logger.info("All the Scrublet results have been selected. Will move to next steps.")
                scrublet_passed = True
        else:
            empty_select_df.to_csv(man_select_path, sep="\t", header=True, index=False)

        if not scrublet_passed:
            # Run scrublet jobs.
            scrublet_files = []
            if config["scrublet_manual"]["run_scrublet_manual"]:
                logger.info("Running scrublet rules with manual selections since 'run_Scrublet_manual' is set to True.")
                scrublet_files = [config["outputs"]["output_dir"] + pool + "/Scrublet_" + str(pctl) + "/Scrublet_doublets_singlets.tsv" for pool in config["scrublet_manual"]["scrublet_manual_threshold_pools"] for pctl in config["scrublet_manual"]["scrublet_manual_threshold_percentiles"]]
                # NOTE: this will fail if you do multiple manual runs (e.g. checking if Scrublet_doublets_singlets.tsv exists). Therefore remove the results file to force a rerun.
                for fname in scrublet_files:
                    if os.path.isfile(fname):
                        os.remove(fname)
            else:
                logger.info("Running the default Scrublet rules since 'run_scrublet_manual' is set to False.")
                scrublet_files = [config["outputs"]["output_dir"] + pool + "/Scrublet_" + str(pctl) + "/Scrublet_doublets_singlets.tsv" for pool in SAMPLES for pctl in config["scrublet"]["percentile"]]
            input_files.extend(scrublet_files)

    if ("DoubletDetection" not in METHODS or doubletdetection_passed) and ("Scrublet" not in METHODS or scrublet_passed):
        return expand(config["outputs"]["output_dir"] + "{pool}/CombinedResults/combined_results_demultiplexing_summary.tsv", pool=SAMPLES)

    return input_files


rule all:
    input:
        combine_results = get_all_input

# Import individual rules
include: "includes/demultiplexing.smk"
include: "includes/doublet_detection.smk"
include: "includes/combine_results.smk"